{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching data from imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fetch():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data()\n",
    "\n",
    "    word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "    index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "    index2word[0] = '[pad]' #padding\n",
    "    index2word[1] = '[bos]' #begin of sentence\n",
    "    index2word[2] = '[oov]' # out of vocabulary\n",
    "    x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
    "    x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_examples(vocabulary, x_train):\n",
    "    binary_vectorizer = CountVectorizer(binary=True, vocabulary=vocabulary.keys())\n",
    "\n",
    "    x_train_binary = binary_vectorizer.fit_transform(x_train)\n",
    "    x_train_binary = x_train_binary.toarray()\n",
    "    return x_train_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ig(classes_vector, feature):\n",
    "        classes = set(classes_vector)\n",
    "\n",
    "        HC = 0\n",
    "        for c in classes:\n",
    "            PC = list(classes_vector).count(c) / len(classes_vector)  # P(C=c)\n",
    "            HC += - PC * math.log(PC, 2)  # H(C)\n",
    "            # print('Overall Entropy:', HC)  # entropy for C variable\n",
    "\n",
    "        feature_values = set(feature)  # 0 or 1 in this example\n",
    "        HC_feature = 0\n",
    "        for value in feature_values:\n",
    "            # pf --> P(X=x)\n",
    "            pf = list(feature).count(value) / len(feature)  # count occurences of value \n",
    "            indices = [i for i in range(len(feature)) if feature[i] == value]  # rows (examples) that have X=x\n",
    "\n",
    "            classes_of_feat = [classes_vector[i] for i in indices]  # category of examples listed in indices above\n",
    "            for c in classes:\n",
    "                # pcf --> P(C=c|X=x)\n",
    "                pcf = classes_of_feat.count(c) / len(classes_of_feat)  # given X=x, count C\n",
    "                if pcf != 0: \n",
    "                    # - P(X=x) * P(C=c|X=x) * log2(P(C=c|X=x))\n",
    "                    temp_H = - pf * pcf * math.log(pcf, 2)\n",
    "                    # sum for all values of C (class) and X (values of specific feature)\n",
    "                    HC_feature += temp_H\n",
    "\n",
    "        ig = HC - HC_feature\n",
    "        return ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(x_train, m, n, k, ig):\n",
    "    # n most frequent\n",
    "    # k less frequent\n",
    "    # ig \n",
    "    \n",
    "    words_frequency_Dict = dict()\n",
    "\n",
    "    for review in x_train:\n",
    "        # I need a list with the distinct words of every review\n",
    "        distinct_words = set(review.split())\n",
    "\n",
    "        for word in distinct_words:\n",
    "            if word in words_frequency_Dict.keys():\n",
    "                words_frequency_Dict[word] += 1\n",
    "            else:\n",
    "                words_frequency_Dict[word] = 1\n",
    "    \n",
    "    words_frequency_Dict.pop('[bos]',' ')\n",
    "    words_frequency_Dict.pop('[pad]',' ')\n",
    "    words_frequency_Dict.pop('[oov]',' ')\n",
    "                \n",
    "    # Sort words based on their frequency in descending order\n",
    "    remaining_words = sorted(words_frequency_Dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "     # Exclude the top n and bottom k words\n",
    "    remaining_words = sorted_words[n:-k] if k > 0 else sorted_words[n:]\n",
    "\n",
    "    \n",
    "    #create new dictionary which shows the IG\n",
    "    IG_Dict = dict()\n",
    "    for i in tqdm(range(len(remaining_words))):\n",
    "        word = [example[i] for example in x_train_binary]\n",
    "        IG_Dict[list(remaining_words.keys())[i]] = IG(y_train, word)\n",
    "\n",
    "    remaining_words = sorted(IG_Dict.items(), key=lambda x: x[1])\n",
    "    remaining_words = remaining_words[:l] \n",
    "\n",
    "    \n",
    "    return remaining_words\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
